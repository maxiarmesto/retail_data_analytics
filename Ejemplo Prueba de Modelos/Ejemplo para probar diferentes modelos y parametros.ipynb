{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_files('Dataset/new_descriptions', shuffle=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bank_Of_America',\n",
       " 'Bealls',\n",
       " 'EBS_Minds_IT',\n",
       " 'ICON_Technologies',\n",
       " 'Lorhan',\n",
       " 'Nordstrom']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'data': dataset['data'], 'target': dataset['target']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.data,\n",
    "    dataset.target,\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    DecisionTreeClassifier(max_depth = 2, random_state=0),\n",
    "    LogisticRegression(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    SVC(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.50      0.11      0.18        18\n",
      "           Bealls       0.75      0.07      0.13        41\n",
      "     EBS_Minds_IT       0.15      0.88      0.26        17\n",
      "ICON_Technologies       0.63      0.92      0.75        26\n",
      "           Lorhan       0.00      0.00      0.00        17\n",
      "        Nordstrom       0.50      0.04      0.07        27\n",
      "\n",
      "        micro avg       0.31      0.31      0.31       146\n",
      "        macro avg       0.42      0.34      0.23       146\n",
      "     weighted avg       0.50      0.31      0.24       146\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00         1\n",
      "           Bealls       1.00      0.12      0.22         8\n",
      "     EBS_Minds_IT       0.25      0.33      0.29         3\n",
      "ICON_Technologies       0.19      1.00      0.32         4\n",
      "           Lorhan       0.00      0.00      0.00         2\n",
      "        Nordstrom       0.00      0.00      0.00         8\n",
      "\n",
      "        micro avg       0.23      0.23      0.23        26\n",
      "        macro avg       0.24      0.24      0.14        26\n",
      "     weighted avg       0.37      0.23      0.15        26\n",
      "\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       1.00      0.94      0.97        18\n",
      "           Bealls       0.87      0.98      0.92        41\n",
      "     EBS_Minds_IT       1.00      0.82      0.90        17\n",
      "ICON_Technologies       0.96      0.88      0.92        26\n",
      "           Lorhan       0.94      1.00      0.97        17\n",
      "        Nordstrom       0.96      0.96      0.96        27\n",
      "\n",
      "        micro avg       0.94      0.94      0.94       146\n",
      "        macro avg       0.96      0.93      0.94       146\n",
      "     weighted avg       0.94      0.94      0.94       146\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00         1\n",
      "           Bealls       0.67      0.75      0.71         8\n",
      "     EBS_Minds_IT       1.00      0.33      0.50         3\n",
      "ICON_Technologies       0.67      1.00      0.80         4\n",
      "           Lorhan       0.00      0.00      0.00         2\n",
      "        Nordstrom       0.62      0.62      0.62         8\n",
      "\n",
      "        micro avg       0.62      0.62      0.62        26\n",
      "        macro avg       0.49      0.45      0.44        26\n",
      "     weighted avg       0.62      0.62      0.59        26\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00        18\n",
      "           Bealls       0.32      1.00      0.48        41\n",
      "     EBS_Minds_IT       1.00      0.41      0.58        17\n",
      "ICON_Technologies       0.00      0.00      0.00        26\n",
      "           Lorhan       0.00      0.00      0.00        17\n",
      "        Nordstrom       1.00      0.37      0.54        27\n",
      "\n",
      "        micro avg       0.40      0.40      0.40       146\n",
      "        macro avg       0.39      0.30      0.27       146\n",
      "     weighted avg       0.39      0.40      0.30       146\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00         1\n",
      "           Bealls       0.33      1.00      0.50         8\n",
      "     EBS_Minds_IT       0.00      0.00      0.00         3\n",
      "ICON_Technologies       0.00      0.00      0.00         4\n",
      "           Lorhan       0.00      0.00      0.00         2\n",
      "        Nordstrom       1.00      0.25      0.40         8\n",
      "\n",
      "        micro avg       0.38      0.38      0.38        26\n",
      "        macro avg       0.22      0.21      0.15        26\n",
      "     weighted avg       0.41      0.38      0.28        26\n",
      "\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       1.00      1.00      1.00        18\n",
      "           Bealls       0.91      1.00      0.95        41\n",
      "     EBS_Minds_IT       1.00      0.88      0.94        17\n",
      "ICON_Technologies       1.00      0.92      0.96        26\n",
      "           Lorhan       1.00      1.00      1.00        17\n",
      "        Nordstrom       1.00      1.00      1.00        27\n",
      "\n",
      "        micro avg       0.97      0.97      0.97       146\n",
      "        macro avg       0.99      0.97      0.98       146\n",
      "     weighted avg       0.98      0.97      0.97       146\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00         1\n",
      "           Bealls       0.58      0.88      0.70         8\n",
      "     EBS_Minds_IT       0.00      0.00      0.00         3\n",
      "ICON_Technologies       0.57      1.00      0.73         4\n",
      "           Lorhan       0.00      0.00      0.00         2\n",
      "        Nordstrom       0.80      0.50      0.62         8\n",
      "\n",
      "        micro avg       0.58      0.58      0.58        26\n",
      "        macro avg       0.33      0.40      0.34        26\n",
      "     weighted avg       0.51      0.58      0.52        26\n",
      "\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       1.00      1.00      1.00        18\n",
      "           Bealls       1.00      1.00      1.00        41\n",
      "     EBS_Minds_IT       1.00      0.88      0.94        17\n",
      "ICON_Technologies       0.93      1.00      0.96        26\n",
      "           Lorhan       1.00      1.00      1.00        17\n",
      "        Nordstrom       1.00      1.00      1.00        27\n",
      "\n",
      "        micro avg       0.99      0.99      0.99       146\n",
      "        macro avg       0.99      0.98      0.98       146\n",
      "     weighted avg       0.99      0.99      0.99       146\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00         1\n",
      "           Bealls       0.50      0.38      0.43         8\n",
      "     EBS_Minds_IT       0.00      0.00      0.00         3\n",
      "ICON_Technologies       0.50      1.00      0.67         4\n",
      "           Lorhan       0.33      0.50      0.40         2\n",
      "        Nordstrom       0.75      0.38      0.50         8\n",
      "\n",
      "        micro avg       0.42      0.42      0.42        26\n",
      "        macro avg       0.35      0.38      0.33        26\n",
      "     weighted avg       0.49      0.42      0.42        26\n",
      "\n",
      "<class 'sklearn.svm.classes.SVC'>\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00        18\n",
      "           Bealls       0.28      1.00      0.44        41\n",
      "     EBS_Minds_IT       0.00      0.00      0.00        17\n",
      "ICON_Technologies       0.00      0.00      0.00        26\n",
      "           Lorhan       0.00      0.00      0.00        17\n",
      "        Nordstrom       0.00      0.00      0.00        27\n",
      "\n",
      "        micro avg       0.28      0.28      0.28       146\n",
      "        macro avg       0.05      0.17      0.07       146\n",
      "     weighted avg       0.08      0.28      0.12       146\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00         1\n",
      "           Bealls       0.31      1.00      0.47         8\n",
      "     EBS_Minds_IT       0.00      0.00      0.00         3\n",
      "ICON_Technologies       0.00      0.00      0.00         4\n",
      "           Lorhan       0.00      0.00      0.00         2\n",
      "        Nordstrom       0.00      0.00      0.00         8\n",
      "\n",
      "        micro avg       0.31      0.31      0.31        26\n",
      "        macro avg       0.05      0.17      0.08        26\n",
      "     weighted avg       0.09      0.31      0.14        26\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       1.00      0.94      0.97        18\n",
      "           Bealls       0.98      1.00      0.99        41\n",
      "     EBS_Minds_IT       1.00      0.88      0.94        17\n",
      "ICON_Technologies       0.87      1.00      0.93        26\n",
      "           Lorhan       1.00      0.94      0.97        17\n",
      "        Nordstrom       1.00      0.96      0.98        27\n",
      "\n",
      "        micro avg       0.97      0.97      0.97       146\n",
      "        macro avg       0.97      0.96      0.96       146\n",
      "     weighted avg       0.97      0.97      0.97       146\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Bank_Of_America       0.00      0.00      0.00         1\n",
      "           Bealls       0.50      0.50      0.50         8\n",
      "     EBS_Minds_IT       0.00      0.00      0.00         3\n",
      "ICON_Technologies       0.25      0.75      0.38         4\n",
      "           Lorhan       0.00      0.00      0.00         2\n",
      "        Nordstrom       1.00      0.50      0.67         8\n",
      "\n",
      "        micro avg       0.42      0.42      0.42        26\n",
      "        macro avg       0.29      0.29      0.26        26\n",
      "     weighted avg       0.50      0.42      0.42        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(str(clf.__class__))\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_train)\n",
    "    print(metrics.classification_report(y_train, y_pred, target_names=dataset['target_names']))\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, y_pred, target_names=dataset['target_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'vect__binary': [True],\n",
    "    'vect__lowercase': [True],\n",
    "    'vect__sublinear_tf': [True, False],\n",
    "    'vect__ngram_range': [(1, 3), (1, 4),(1, 7)],\n",
    "    'vect__strip_accents': ['ascii'],\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'vect__max_df': [1.],\n",
    "    'clf__multi_class' : ['ovr', 'crammer_singer'],\n",
    "    'clf__random_state': [0],\n",
    "    'clf__fit_intercept':[True, False],\n",
    "    'clf__loss':['hinge', 'squared_hinge'],\n",
    "    'clf__C':[1.0, 0.1],\n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "results = []\n",
    "print(len(params_list))\n",
    "\n",
    "for params in params_list:\n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    result = {'acc': acc, 'f1': f1}\n",
    "        \n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>clf__fit_intercept</th>\n",
       "      <th>clf__loss</th>\n",
       "      <th>clf__multi_class</th>\n",
       "      <th>clf__random_state</th>\n",
       "      <th>f1</th>\n",
       "      <th>vect__analyzer</th>\n",
       "      <th>vect__binary</th>\n",
       "      <th>vect__lowercase</th>\n",
       "      <th>vect__max_df</th>\n",
       "      <th>vect__min_df</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>vect__strip_accents</th>\n",
       "      <th>vect__sublinear_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>word</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>ascii</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc  clf__C  clf__fit_intercept      clf__loss clf__multi_class  \\\n",
       "24  0.576923     1.0                True          hinge   crammer_singer   \n",
       "25  0.576923     1.0                True          hinge   crammer_singer   \n",
       "26  0.576923     1.0                True          hinge   crammer_singer   \n",
       "27  0.576923     1.0                True          hinge   crammer_singer   \n",
       "28  0.576923     1.0                True          hinge   crammer_singer   \n",
       "29  0.576923     1.0                True          hinge   crammer_singer   \n",
       "60  0.576923     1.0                True  squared_hinge   crammer_singer   \n",
       "61  0.576923     1.0                True  squared_hinge   crammer_singer   \n",
       "62  0.576923     1.0                True  squared_hinge   crammer_singer   \n",
       "63  0.576923     1.0                True  squared_hinge   crammer_singer   \n",
       "\n",
       "    clf__random_state        f1 vect__analyzer  vect__binary  vect__lowercase  \\\n",
       "24                  0  0.490842           word          True             True   \n",
       "25                  0  0.490842           word          True             True   \n",
       "26                  0  0.490842           word          True             True   \n",
       "27                  0  0.490842           word          True             True   \n",
       "28                  0  0.490842           word          True             True   \n",
       "29                  0  0.490842           word          True             True   \n",
       "60                  0  0.490842           word          True             True   \n",
       "61                  0  0.490842           word          True             True   \n",
       "62                  0  0.490842           word          True             True   \n",
       "63                  0  0.490842           word          True             True   \n",
       "\n",
       "    vect__max_df  vect__min_df vect__ngram_range vect__strip_accents  \\\n",
       "24           1.0             2            (1, 3)               ascii   \n",
       "25           1.0             2            (1, 3)               ascii   \n",
       "26           1.0             2            (1, 4)               ascii   \n",
       "27           1.0             2            (1, 4)               ascii   \n",
       "28           1.0             2            (1, 7)               ascii   \n",
       "29           1.0             2            (1, 7)               ascii   \n",
       "60           1.0             2            (1, 3)               ascii   \n",
       "61           1.0             2            (1, 3)               ascii   \n",
       "62           1.0             2            (1, 4)               ascii   \n",
       "63           1.0             2            (1, 4)               ascii   \n",
       "\n",
       "    vect__sublinear_tf  \n",
       "24                True  \n",
       "25               False  \n",
       "26                True  \n",
       "27               False  \n",
       "28                True  \n",
       "29               False  \n",
       "60                True  \n",
       "61               False  \n",
       "62                True  \n",
       "63               False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
